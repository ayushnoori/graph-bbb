{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Notes\n",
    "**Ayush Noori**\n",
    "\n",
    "This file contains notes and tests for training an XGBoost model **outside** of an Optuna loop. These tests were used to write `train_xgboost.ipynb`. Please see that file for the final version of the code.\n",
    "\n",
    "First, I load the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # inline plots\n",
    "%matplotlib inline\n",
    "\n",
    "# TDC library\n",
    "from tdc.benchmark_group import admet_group\n",
    "from tdc.chem_utils import MolConvert\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# import Optuna\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import optuna.visualization.matplotlib as oviz\n",
    "\n",
    "# logging to show Optuna output\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# time management\n",
    "from datetime import datetime\n",
    "\n",
    "# create time object used for file names\n",
    "my_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    }
   ],
   "source": [
    "group = admet_group(path = 'data/')\n",
    "predictions_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I retrieve the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed and benchmark in benchmark\n",
    "seed = 1\n",
    "benchmark = group.get('BBB_Martins') \n",
    "    \n",
    "# all benchmark names in a benchmark group are stored in group.dataset_names\n",
    "predictions = {}\n",
    "name = benchmark['name']\n",
    "train_val, test = benchmark['train_val'], benchmark['test']\n",
    "# train, valid = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I check the eligible conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SELFIES',\n",
       " 'Graph2D',\n",
       " 'PyG',\n",
       " 'DGL',\n",
       " 'ECFP2',\n",
       " 'ECFP4',\n",
       " 'ECFP6',\n",
       " 'MACCS',\n",
       " 'Daylight',\n",
       " 'RDKit2D',\n",
       " 'Morgan',\n",
       " 'PubChem']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MolConvert.eligible_format(src = \"SMILES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I train the model using `train` and `valid` variables, evaluate on the `test` variable, then save the `test` predictions in `y_pred_test`. First, I convert the SMILES structures to fingerprints. Note that conversion from `SMILES` to `RDKit2D` requires `pip install git+https://github.com/bp-kelley/descriptastorus` and `pip install pandas-flavor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.921082</td>\n",
       "      <td>0.077700</td>\n",
       "      <td>0.324169</td>\n",
       "      <td>0.379878</td>\n",
       "      <td>0.467164</td>\n",
       "      <td>0.240353</td>\n",
       "      <td>0.344156</td>\n",
       "      <td>0.422452</td>\n",
       "      <td>0.438361</td>\n",
       "      <td>0.462373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.593061e-17</td>\n",
       "      <td>5.766101e-14</td>\n",
       "      <td>2.957989e-11</td>\n",
       "      <td>0.168378</td>\n",
       "      <td>0.16738</td>\n",
       "      <td>1.481515e-18</td>\n",
       "      <td>2.324150e-16</td>\n",
       "      <td>4.703598e-08</td>\n",
       "      <td>0.166633</td>\n",
       "      <td>0.322648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.987144</td>\n",
       "      <td>0.031450</td>\n",
       "      <td>0.012150</td>\n",
       "      <td>0.007312</td>\n",
       "      <td>0.016454</td>\n",
       "      <td>0.007969</td>\n",
       "      <td>0.006128</td>\n",
       "      <td>0.010915</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.020255</td>\n",
       "      <td>...</td>\n",
       "      <td>1.593061e-17</td>\n",
       "      <td>5.766101e-14</td>\n",
       "      <td>2.957989e-11</td>\n",
       "      <td>0.168378</td>\n",
       "      <td>0.16738</td>\n",
       "      <td>1.481515e-18</td>\n",
       "      <td>2.324150e-16</td>\n",
       "      <td>4.703598e-08</td>\n",
       "      <td>0.166633</td>\n",
       "      <td>0.790579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.952163</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.040727</td>\n",
       "      <td>0.064078</td>\n",
       "      <td>0.045419</td>\n",
       "      <td>0.025158</td>\n",
       "      <td>0.042085</td>\n",
       "      <td>0.026486</td>\n",
       "      <td>0.113303</td>\n",
       "      <td>0.068544</td>\n",
       "      <td>...</td>\n",
       "      <td>1.593061e-17</td>\n",
       "      <td>5.766101e-14</td>\n",
       "      <td>2.957989e-11</td>\n",
       "      <td>0.168378</td>\n",
       "      <td>0.16738</td>\n",
       "      <td>1.481515e-18</td>\n",
       "      <td>2.324150e-16</td>\n",
       "      <td>4.703598e-08</td>\n",
       "      <td>0.166633</td>\n",
       "      <td>0.858166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.954015</td>\n",
       "      <td>0.038479</td>\n",
       "      <td>0.025235</td>\n",
       "      <td>0.013677</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>0.020597</td>\n",
       "      <td>0.013406</td>\n",
       "      <td>0.008540</td>\n",
       "      <td>0.011734</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>...</td>\n",
       "      <td>1.593061e-17</td>\n",
       "      <td>5.766101e-14</td>\n",
       "      <td>2.957989e-11</td>\n",
       "      <td>0.168378</td>\n",
       "      <td>0.16738</td>\n",
       "      <td>1.481515e-18</td>\n",
       "      <td>2.324150e-16</td>\n",
       "      <td>4.703598e-08</td>\n",
       "      <td>0.166633</td>\n",
       "      <td>0.575999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.950627</td>\n",
       "      <td>0.115216</td>\n",
       "      <td>0.268876</td>\n",
       "      <td>0.252717</td>\n",
       "      <td>0.271183</td>\n",
       "      <td>0.201013</td>\n",
       "      <td>0.178351</td>\n",
       "      <td>0.288253</td>\n",
       "      <td>0.140577</td>\n",
       "      <td>0.198425</td>\n",
       "      <td>...</td>\n",
       "      <td>1.593061e-17</td>\n",
       "      <td>5.766101e-14</td>\n",
       "      <td>2.957989e-11</td>\n",
       "      <td>0.168378</td>\n",
       "      <td>0.16738</td>\n",
       "      <td>1.481515e-18</td>\n",
       "      <td>2.324150e-16</td>\n",
       "      <td>4.703598e-08</td>\n",
       "      <td>0.166633</td>\n",
       "      <td>0.490319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.921082  0.077700  0.324169  0.379878  0.467164  0.240353  0.344156   \n",
       "1  0.987144  0.031450  0.012150  0.007312  0.016454  0.007969  0.006128   \n",
       "2  0.952163  0.031338  0.040727  0.064078  0.045419  0.025158  0.042085   \n",
       "3  0.954015  0.038479  0.025235  0.013677  0.008824  0.020597  0.013406   \n",
       "4  0.950627  0.115216  0.268876  0.252717  0.271183  0.201013  0.178351   \n",
       "\n",
       "        7         8         9    ...           190           191  \\\n",
       "0  0.422452  0.438361  0.462373  ...  1.593061e-17  5.766101e-14   \n",
       "1  0.010915  0.009768  0.020255  ...  1.593061e-17  5.766101e-14   \n",
       "2  0.026486  0.113303  0.068544  ...  1.593061e-17  5.766101e-14   \n",
       "3  0.008540  0.011734  0.005801  ...  1.593061e-17  5.766101e-14   \n",
       "4  0.288253  0.140577  0.198425  ...  1.593061e-17  5.766101e-14   \n",
       "\n",
       "            192       193      194           195           196           197  \\\n",
       "0  2.957989e-11  0.168378  0.16738  1.481515e-18  2.324150e-16  4.703598e-08   \n",
       "1  2.957989e-11  0.168378  0.16738  1.481515e-18  2.324150e-16  4.703598e-08   \n",
       "2  2.957989e-11  0.168378  0.16738  1.481515e-18  2.324150e-16  4.703598e-08   \n",
       "3  2.957989e-11  0.168378  0.16738  1.481515e-18  2.324150e-16  4.703598e-08   \n",
       "4  2.957989e-11  0.168378  0.16738  1.481515e-18  2.324150e-16  4.703598e-08   \n",
       "\n",
       "        198       199  \n",
       "0  0.166633  0.322648  \n",
       "1  0.166633  0.790579  \n",
       "2  0.166633  0.858166  \n",
       "3  0.166633  0.575999  \n",
       "4  0.166633  0.490319  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define fingerprint\n",
    "mol_dst = 'RDKit2D'\n",
    "# mol_dst = trial.suggest_categorical(\"mol_dst\", [\"ECFP2\", \"ECFP4\", \"MACCS\", \"Morgan\", \"Daylight\", \"RDKit2D\"])\n",
    "\n",
    "# convert fingerprint\n",
    "converter = MolConvert(src = 'SMILES', dst = mol_dst)\n",
    "train_val_features = pd.DataFrame([converter(x) for x in train_val['Drug'][0:5]])\n",
    "# test_features = pd.DataFrame([converter(x) for x in test['Drug']])\n",
    "train_val_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I convert the datasets into an optimized data structure called `DMatrix` that XGBoost supports for performance and efficiency gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimized DMatrix object\n",
    "dtrain_val = xgb.DMatrix(train_val_features, label = train_val['Y'])\n",
    "dtest = xgb.DMatrix(test_features, label = test['Y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter definition code below was inspired by [this post](https://medium.com/optuna/using-optuna-to-optimize-xgboost-hyperparameters-63bfcdfd3407) with [this source code](https://gist.github.com/Crissman/4ddeec6718627ecef46f863e1bf90424#file-xgboost_integration-py). See [the documentation](https://xgboost.readthedocs.io/en/latest/parameter.html) for a full list of possible parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the XGBoost parameters\n",
    "\n",
    "# params = {\n",
    "#         \"objective\": \"binary:logistic\",\n",
    "#         \"eval_metric\": \"auc\",\n",
    "#         \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "#         \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 1.0),\n",
    "#         \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-8, 1.0),\n",
    "#     }\n",
    "\n",
    "# if params[\"booster\"] == \"gbtree\" or params[\"booster\"] == \"dart\":\n",
    "#     params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 9)\n",
    "#     params[\"eta\"] = trial.suggest_loguniform(\"eta\", 1e-8, 1.0)\n",
    "#     params[\"gamma\"] = trial.suggest_loguniform(\"gamma\", 1e-8, 1.0)\n",
    "#     params[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "\n",
    "# if params[\"booster\"] == \"dart\":\n",
    "#     params[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "#     params[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "#     params[\"rate_drop\"] = trial.suggest_loguniform(\"rate_drop\", 1e-8, 1.0)\n",
    "#     params[\"skip_drop\"] = trial.suggest_loguniform(\"skip_drop\", 1e-8, 1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outside of an Optuna trial, use the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"lambda\": 1e-6,\n",
    "        \"alpha\": 1e-6,\n",
    "        \"max_depth\": 4,\n",
    "        # \"eta\": 1e-6,\n",
    "        # \"gamma\": 1e-6,\n",
    "        \"grow_policy\": \"depthwise\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I define the XGBoost regressor and train the model using 5-fold cross-validation. The `xgb.cv()` function returns the evaluation history; i.e., the last boosting round metric is the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.983556</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.900754</td>\n",
       "      <td>0.010689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.984199</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.901658</td>\n",
       "      <td>0.010538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.984733</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.902352</td>\n",
       "      <td>0.010570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.985151</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.903249</td>\n",
       "      <td>0.010432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.985599</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.905091</td>\n",
       "      <td>0.010178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
       "37        0.983556       0.002102       0.900754      0.010689\n",
       "38        0.984199       0.002078       0.901658      0.010538\n",
       "39        0.984733       0.001969       0.902352      0.010570\n",
       "40        0.985151       0.002021       0.903249      0.010432\n",
       "41        0.985599       0.001994       0.905091      0.010178"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform cross-validation\n",
    "cv_results = xgb.cv(dtrain = dtrain_val, params = params, nfold = 5, \\\n",
    "    num_boost_round = 100, early_stopping_rounds = 10, metrics = \"auc\", as_pandas = True, seed = seed)\n",
    "cv_results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"grow_policy\", \"max_depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train final model based on parameters in Optuna trial\n",
    "xgb_model = xgb.train(dtrain = dtrain_val, params = params, num_boost_round = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41    0.905091\n",
       "Name: test-auc-mean, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# report the final boosting metric as the summary metric for this Optuna trial\n",
    "test_auc_mean = cv_results[\"test-auc-mean\"].tail(1)\n",
    "test_auc_mean\n",
    "\n",
    "# in Optuna loop\n",
    "# return xgb_model, test_auc_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is for an Optuna loop - do not run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training function\n",
    "def train_xgboost(trial):\n",
    "\n",
    "    return xgb_model, test_auc_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Optuna `objective` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories\n",
    "optuna_dir = \"optuna/\"\n",
    "model_dir = optuna_dir + \"models/\"\n",
    "study_dir = optuna_dir + \"database/\"\n",
    "\n",
    "# define objective function\n",
    "def objective(trial):\n",
    "\n",
    "    # start the training loop\n",
    "    trial_xgb_model, trial_test_auc_mean = train_xgboost(trial)\n",
    "\n",
    "    # save model for this loop\n",
    "    trial_xgb_model.save_model(model_dir + \"xgboost_model_{}.json\".format(trial.number))\n",
    "\n",
    "    return trial_test_auc_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Optuna trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-04 14:55:48,669]\u001b[0m A new study created in RDB with name: xgboost-study\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new study created in RDB with name: xgboost-study\n",
      "A new study created in RDB with name: xgboost-study\n",
      "A new study created in RDB with name: xgboost-study\n",
      "A new study created in RDB with name: xgboost-study\n",
      "A new study created in RDB with name: xgboost-study\n",
      "A new study created in RDB with name: xgboost-study\n",
      "A new study created in RDB with name: xgboost-study\n",
      "A new study created in RDB with name: xgboost-study\n",
      "A new study created in RDB with name: xgboost-study\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-04 14:55:48,877]\u001b[0m Trial 0 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 0 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 0 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 0 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 0 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 0 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 0 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 0 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 0 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-04 14:55:49,245]\u001b[0m Trial 1 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 1 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 1 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 1 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 1 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 1 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 1 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 1 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 1 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-04 14:55:49,627]\u001b[0m Trial 2 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 2 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 2 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 2 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 2 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 2 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 2 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 2 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n",
      "Trial 2 finished with value: 0.9050908308634998 and parameters: {}. Best is trial 0 with value: 0.9050908308634998.\n"
     ]
    }
   ],
   "source": [
    "# add stream handler of stdout to show the messages\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# create study\n",
    "study_name = \"xgboost-study\"  # unique identifier of the study\n",
    "storage_name = \"sqlite:///{}.db\".format(study_dir + study_name)\n",
    "study = optuna.create_study(direction = \"maximize\", sampler = TPESampler(seed = 1234, multivariate = True), study_name = study_name, storage = storage_name, load_if_exists = False)\n",
    "\n",
    "# optimize hyperparameters\n",
    "study.optimize(objective, n_trials = 3, gc_after_trial = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, I output Optuna results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Study Statistics:\n",
      "- Finished Trials:  3\n",
      "- Pruned Trials:  0\n",
      "- Complete Trials:  3\n",
      "\n",
      "Best Trial:\n",
      "- Number:  0\n",
      "- Value:  0.9050908308634998\n",
      "- Hyperparameters: \n"
     ]
    }
   ],
   "source": [
    "# get pruned and complete trials\n",
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "# print print study statistics\n",
    "print(\"\\nStudy Statistics:\")\n",
    "print(\"- Finished Trials: \", len(study.trials))\n",
    "print(\"- Pruned Trials: \", len(pruned_trials))\n",
    "print(\"- Complete Trials: \", len(complete_trials))\n",
    "\n",
    "print(\"\\nBest Trial:\")\n",
    "best_trial = study.best_trial\n",
    "print(\"- Number: \", best_trial.number)\n",
    "print(\"- Value: \", best_trial.value)\n",
    "print(\"- Hyperparameters: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"   - {}: {}\".format(key, value))\n",
    "\n",
    "# save and view output\n",
    "study_results = study.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\"))\n",
    "study_results.to_csv(optuna_dir + \"{}.{}_{}.{}.{}_OptunaHistory.csv\".format(my_time.hour, my_time.minute, my_time.month, my_time.day, my_time.year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I visualize Optuna trial results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = oviz.plot_param_importances(study)\n",
    "v2 = oviz.plot_optimization_history(study)\n",
    "v3 = oviz.plot_slice(study)\n",
    "\n",
    "def fig_name(name):\n",
    "    return(optuna_dir + \"output/\" + \"{}.{}_{}.{}.{}_{}.pdf\".format(my_time.hour, my_time.minute, my_time.month, my_time.day, my_time.year, name))\n",
    "\n",
    "v1.figure.savefig(fig_name(\"HyperparameterImportance\"))\n",
    "v2.figure.savefig(fig_name(\"OptimizationHistory\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I train a new model based on the best trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train new model based on the best trial\n",
    "best_xgb_model = xgb.Booster()\n",
    "best_xgb_model.load_model(model_dir + \"xgboost_model_{}.json\".format(best_trial.number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I evaluate on the independent test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 88.,  12.,   7.,  10.,   2.,   5.,  11.,   5.,  12., 254.]),\n",
       " array([3.3818278e-11, 1.0000000e-01, 2.0000000e-01, 3.0000001e-01,\n",
       "        4.0000001e-01, 5.0000000e-01, 6.0000002e-01, 6.9999999e-01,\n",
       "        8.0000001e-01, 8.9999998e-01, 1.0000000e+00], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "y_pred_test = best_xgb_model.predict(dtest)\n",
    "plt.hist(y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I append the predictions to the `predictions_list` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[name] = y_pred_test\n",
    "predictions_list.append(predictions)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee86a5705781cdc5693b22e698b5956b61fc6bfa2e3dcdcaa637adf8210aae45"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('gnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
