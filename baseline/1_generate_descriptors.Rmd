---
title: Generate Molecular Descriptors
subtitle: Ayush Noori
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
    toc: yes
editor_options:
  chunk_output_type: inline
---

```{r setup, include = FALSE}
# knitr::opts_chunk$set(message=FALSE, warning=FALSE)
```

# Dependencies

Load requisite packages and define directories.

```{r load-packages, message=FALSE, warning=FALSE}

# data manipulation
library(data.table)
library(purrr)
library(magrittr)
library(stringi)

# R interface to Java CDK chemoinformatics framework
library(rcdk)

# molecular fingerprints
library(fingerprint)

# ML libraries
library(caret)
library(xgboost)

# data visualization
library(ggplot2)

# source utilities package
library(brainstorm)

```

Note that directories are relative to the R project path.

```{r define-directores}

# set directories
ddir = file.path("scripts", "data")
rdir = file.path("baseline", "results")

# set seed
set.seed(42)

```

# Read Data

Read data downloaded from separate Python script.

```{r read-data}

dat = fread(file.path(ddir, "bbb_martins.tab")) %>%
  .[, ID := stri_rand_strings(nrow(.), 6, pattern = "[A-Za-z]")] %>%
  setcolorder("ID") %>%
  .[, Y := factor(Y, levels = 0:1, labels = c("N", "Y"))]

```

# Generate Descriptors

Generate molecular descriptors.

```{r generate-descriptors}

# convert molecule to molecular formula
sp = get.smiles.parser()
mols = parse.smiles(dat$Drug)

# generate MACCS fingnerprints for all the molecules
fps = map(mols, ~get.fingerprint(.x, type = "maccs"))

# convert fingerprints to matrix
fp_mtx = fp.to.matrix(fps)
rownames(fp_mtx) = dat$ID
colnames(fp_mtx) = seq(1:ncol(fp_mtx))

```

# Train Model

Partition data.

```{r partition-data}

# partition data
train_vals = dat[createDataPartition(Y, p = 0.8, list = FALSE), ID]

# create partition variable
dat %>%
  .[, Partition := "Test"] %>%
  .[ID %in% train_vals, Partition := "Train"]

# split datasets
train_dat = fp_mtx[dat$Partition == "Train", ]
test_dat = fp_mtx[dat$Partition == "Test", ]

# get labels
train_lab = as.numeric(dat[Partition == "Train", Y]) - 1
test_lab = as.numeric(dat[Partition == "Test", Y]) - 1

```

Estimate the pre-processing transformation (remove zero variance) from the training data, then apply to all data. Add `"center", "scale"` to the `method` argument of `preProcess()` to center and scale the data.

```{r pre-process}

# normalize data
vars = colnames(train_dat)
normalize = preProcess(train_dat, method = c("zv"), verbose = TRUE)

# apply transformation
train_dat = predict(normalize, train_dat)
test_dat = predict(normalize, test_dat)

```

Train `xgboost` GBM model.

``` {r xgboost}

# construct xgb.DMatirx object
xgb_train = xgb.DMatrix(data = train_dat, label = train_lab)
xgb_test = xgb.DMatrix(data = test_dat, label = test_lab)

# define watch list
# watchlist = list(train = xgb_train, test = xgb_test)

# fit XGBoost model, could use watchlist = watchlist for validation
xgb_model = xgb.train(data = xgb_train, max.depth = 3, nrounds = 70)

# compute predictions
xgb_pred = predict(xgb_model, xgb_test)

# get confusion matrix
xgb_cm = confusionMatrix(as.factor(round(xgb_pred)), as.factor(test_lab))
print(xgb_cm)

```

Train model on training set.

```{r train-model}

# establish 10-fold cross validation to determine the out-of-sample error
tC = trainControl(method = "cv", number = 10, savePredictions = TRUE, classProbs = TRUE, verboseIter = TRUE)

# train GBM model on training set
gbm_model = train(x = train_dat, y = dat[Partition %in% c("Train", "Validation"), Y], method = "gbm", trControl = tC)

```

Evaluate model on test set.

```{r evaluate-model}

# evaluate GBM model on test set
gbm_pred = predict(gbm_model, test_dat)
gbm_cm = confusionMatrix(gbm_pred, dat[Partition == "Test", Y])

```